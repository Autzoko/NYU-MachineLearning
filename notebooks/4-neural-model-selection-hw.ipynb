{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCK20M0wyFbl"
      },
      "source": [
        "# Model Order Selection for Neural Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gStqeTWGyFbm"
      },
      "source": [
        "**Name**: \\[Fill in your name here\\] **Net ID**: \\[Fill in your net ID here\\]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN7bwoNZyFbm"
      },
      "source": [
        "Make a copy of this notebook in your own Google Drive and, as you work through it, fill in missing code and answers to the questions.\n",
        "\n",
        "After you are finished, you will copy your answers from individual sections *and* a copy of the entire notebook into PrairieLearn for submission. (Note that the PrairieLearn autograder will expect that you have used exactly the variable names shown in this template notebook.)\n",
        "\n",
        "Answers to open-ended questions (e.g. “Comment on the results..”) must be **in your own words**, reflecting your own interpretation and understanding, and must refer to specific results (including numeric values) you obtained in this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sgtAF8DyFbm"
      },
      "source": [
        "**Attribution**: This notebook is a slightly adapted version of the [model order selection lab assignment](https://github.com/sdrangan/introml/blob/master/unit04_model_sel/lab_neural_partial.ipynb) by Prof. Sundeep Rangan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyR3qhdRyFbm"
      },
      "source": [
        "Machine learning is a key tool for neuroscientists to understand how sensory and motor signals are encoded in the brain. In addition to improving our scientific understanding of neural phenomena, understanding neural encoding is critical for brain machine interfaces. In this notebook, you will use model selection for performing some simple analysis on real neural signals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTDBuiPxyFbm"
      },
      "source": [
        "## Loading the data\n",
        "\n",
        "The data in this lab comes from neural recordings described in:\n",
        "\n",
        "<a href=\"http://jn.physiology.org/content/106/2/764.short\"> Stevenson, Ian H., et al. “Statistical assessment of the stability of neural movement representations.” Journal of neurophysiology 106.2 (2011): 764-774</a>\n",
        "\n",
        "Neurons are the basic information processing units in the brain. Neurons communicate with one another via *spikes* or *action potentials* which are brief events where voltage in the neuron rapidly rises then falls. These spikes trigger the electro-chemical signals between one neuron and another. In this experiment, the spikes were recorded from 196 neurons in the primary motor cortex (M1) of a monkey using an electrode array implanted onto the surface of a monkey's brain. During the recording, the monkey performed several reaching tasks and the position and velocity of the hand was recorded as well.\n",
        "\n",
        "The goal of the experiment is to try to *read the monkey's brain*: That is, predict the hand motion from the neural signals from the motor cortex.\n",
        "\n",
        "We first load the key packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwjoyBetyFbn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import pickle\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split, KFold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPpfm9ZoyFbn"
      },
      "source": [
        "The full data is available on the CRCNS website <http://crcns.org/data-sets/movements/dream>. However, the raw data files can be quite large. To make the lab easier, the [Kording lab](http://kordinglab.com/) at UPenn has put together an excellent [repository](https://github.com/KordingLab/Neural_Decoding) where they have created simple pre-processed versions of the data. You can download the file `example_data_s1.pickle` from the [Dropbox link](https://www.dropbox.com/sh/n4924ipcfjqc0t6/AADOv9JYMUBK1tlg9P71gSSra/example_data_s1.pickle?dl=0). Alternatively, you can directly run the following command. This may take a little while to download since the file is 26 MB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0Osc-ldyFbn"
      },
      "outputs": [],
      "source": [
        "!wget 'https://www.dropbox.com/sh/n4924ipcfjqc0t6/AADOv9JYMUBK1tlg9P71gSSra/example_data_s1.pickle?dl=1' -O example_data_s1.pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atetAcrVyFbn"
      },
      "source": [
        "The file is a *pickle* data structure, which uses the Python package `pickle` to serialize Python objects into data files. Once you have downloaded the file, you can run the following command to retrieve the data from the pickle file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoTy6kTkyFbn"
      },
      "outputs": [],
      "source": [
        "with open('example_data_s1.pickle', 'rb') as fp:\n",
        "    X,y = pickle.load(fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43qJVBIDyFbo"
      },
      "source": [
        "The matrix `X` is matrix of spike counts from different neurons, where `X[i,j]` is the number of spikes from neuron `j` in time bin `i`.\n",
        "\n",
        "The matrix `y` has two columns:\n",
        "\n",
        "-   `y[i,0] =` velocity of the monkey's hand in the x-direction in time bin `i`\n",
        "-   `y[i,1] =` velocity of the monkey's hand in the y-direction in time bin `i`\n",
        "\n",
        "Our goal will be to predict `y` from `X`.\n",
        "\n",
        "Each time bin represent `tsamp=0.05` seconds of time. Using `X.shape` and `y.shape`, we can compute and print:\n",
        "\n",
        "-   `nt =` the total number of time bins\n",
        "-   `nneuron =` the total number of neurons\n",
        "-   `nout =` the total number of output variables to track = number of columns in `y`\n",
        "-   `ttotal =` total time of the experiment is seconds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daS7mjQWyFbo"
      },
      "outputs": [],
      "source": [
        "tsamp = 0.05  # sampling time in seconds\n",
        "\n",
        "nt, nneuron = X.shape\n",
        "nout = y.shape[1]\n",
        "ttotal = nt*tsamp\n",
        "\n",
        "print('Number of neurons = %d' % nneuron)\n",
        "print('Number of time samples = %d' % nt)\n",
        "print('Number of outputs = %d' % nout)\n",
        "print('Total time (secs) = %f' % ttotal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve1YZWCWyFbo"
      },
      "source": [
        "Then, we can plot the velocity against time, for each direction, for the first 1000 samples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwdT7TwxyFbo"
      },
      "outputs": [],
      "source": [
        "t_cutoff = 1000\n",
        "directions = ['x', 'y']\n",
        "\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(15,7))\n",
        "for n in range(nout):\n",
        "  sns.lineplot(x=np.arange(0, t_cutoff)*tsamp, y=y[0:t_cutoff, n], label=directions[n], ax=axes[n]);\n",
        "\n",
        "  axes[n].set_ylabel(\"Velocity\")\n",
        "  axes[n].set_xlabel(\"Time (s)\")\n",
        "  axes[n].set_ylim(-50,50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peLK98pUyFbo"
      },
      "source": [
        "We can also “zoom in” on a small slice of time in which the monkey is moving the hand, and see the neural activity at the same time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FingyXWYyFbo"
      },
      "outputs": [],
      "source": [
        "t_start = 490\n",
        "t_end = 580\n",
        "\n",
        "fig, axes = plt.subplots(nrows=7, ncols=8, figsize=(15,15))\n",
        "\n",
        "# Setting the range for all axes\n",
        "plt.setp(axes, xlim=(t_start, t_end), ylim=(0,12));\n",
        "\n",
        "for n in range(nout):\n",
        "  sns.lineplot(x=np.arange(t_start, t_end)*tsamp, y=y[t_start:t_end, n], ax=axes[n//2,n%2], color='red', label=directions[n])\n",
        "  plt.setp(axes[n//2,n%2], xlim=(t_start*tsamp, t_end*tsamp), ylim=(-50, +50));\n",
        "\n",
        "for n in range(nneuron):\n",
        "  sns.lineplot(x=np.arange(t_start, t_end)*tsamp, y=X[t_start:t_end, n], ax=axes[(n+2)//8,(n+2)%8], label=\"n%d\" % n, color='grey')\n",
        "  plt.setp(axes[(n+2)//8,(n+2)%8], xlim=(t_start*tsamp, t_end*tsamp), ylim=(0, +15));\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-Y6XQh-yFbo"
      },
      "source": [
        "## 1. Fitting a linear model\n",
        "\n",
        "Let’s first try a linear regression model to fit the data.\n",
        "\n",
        "To start, we will split the data into a training set and a test set. We’l fit the model on the training set and then use the test set to estimate the model performance on new, unseen data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhrND1I2yFbo"
      },
      "source": [
        "**To shuffle or not to shuffle?**\n",
        "\n",
        "The `train_test_split` function has an optional `shuffle` argument.\n",
        "\n",
        "-   If you use `shuffle=False`, then `train_test_split` will take the first part of the data as the training set and the second part of the data as the test set, according to the ratio you specify in `test_size` or `train_size`.\n",
        "-   If you use `shuffle=True`, then `train_test_split` will first randomly shuffle the data. Then, it will take the first part of the *shuffled* data as the training set and the second part of the *shuffled* data as the test set, according to the ratio you specify in `test_size` or `train_size`.\n",
        "\n",
        "According to the function [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), by default, `shuffle` is `True`:\n",
        "\n",
        "> **shuffle: bool, default=True**\n",
        ">\n",
        "> Whether or not to shuffle the data before splitting. If shuffle=False then stratify must be None.\n",
        "\n",
        "so if you do not specify anything related to `shuffle`, your data will be randomly shuffled before it is split into training and test data.\n",
        "\n",
        "Under what conditions should you shuffle data? Suppose your dataset includes samples of a medical experiment on 1000 subjects, and the first 500 samples in the data are from male subjects while the second 500 samples are from female subjects. If you set `shuffle=False`, then your training set would have a much higher proportion of male subjects than your test set (with the specific numbers depending on the ratio you specify).\n",
        "\n",
        "On the other hand, suppose your dataset includes stock prices at closing time, with each sample representing a different date (in order). If you allow `train_test_split` to shuffle the data, then your model will be allowed to “learn” stock prices using prices from the day *after* the one it is trying to predict! Obviously, your model won’t be able to learn from future dates in production, so it shouldn’t be allowed to in the evaluation stage, either. (Predicting the past using the future is considered a type of data leakage.)\n",
        "\n",
        "With this in mind, it is usually inappropriate to shuffle time series data when splitting it up into smaller sets for training, validation, or testing.\n",
        "\n",
        "(There are more sophisticated ways to handle splitting time series data, but for now, splitting it up the usual way, just without shuffling first, will suffice.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nb0GpOUyFbo"
      },
      "source": [
        "Given the discussion above, use the `train_test_split` function to split the data into training and test sets, but with no shuffling. Let `Xtr,ytr` be the training data set and `Xts,yts` be the test data set. Use `test_size=0.33` so 1/3 of the data is used for evaluating the model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hmz4-2TtyFbo"
      },
      "outputs": [],
      "source": [
        "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
        "\n",
        "# TODO: Split data intro training and test sets\n",
        "# Xtr ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZW--kBpGyFbo"
      },
      "source": [
        "Now, fit a linear regression on the training data `Xtr,ytr`. Make a prediction `yhat_no_dly` using the test data, `Xts`. Compare `yhat_no_dly` to `yts` to measure `rsq_no_dly`, the R2 value. Use the sklearn `r2_score` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-4iHiRbyFbp"
      },
      "outputs": [],
      "source": [
        "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
        "\n",
        "# TODO: Fit a linear model\n",
        "# yhat_no_dly = ...\n",
        "# rsq_no_dly = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rngOQsAyFbp"
      },
      "source": [
        "Print the `rsq_no_dly` value. You should get `rsq_no_dly` of around `0.45`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCA-n7L2yFbp"
      },
      "outputs": [],
      "source": [
        "rsq_no_dly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eewWl7aAyFbp"
      },
      "source": [
        "It is useful to plot the predicted vs. actual values. Use the test data for this visualization. Create a scatter plot of predicted values ($\\hat{y}$) on the vertical axis, and actual values ($y$) on the horizontal axis. Since we have two predicted values for each sample - the velocity in the X direction and the velocity in the Y direction - you should make two subplots,\n",
        "\n",
        "-   one of predicted X direction vs. actual X direction,\n",
        "-   one of predicted Y direction vs. actual Y direction\n",
        "\n",
        "Make sure both axes use the same scale (the range of the vertical axis should be the same as the range of the horizontal axis) *and* that all subplots use the same scale. Label each axes, and each plot (indicate which plot shows the velocity in the X direction and which shows the velocity in the Y direction!) Also, the plot area for each subplot should be square-shaped (similar height and width) in order to make the relevant trend easier to see."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUZQ_6l_yFbp"
      },
      "outputs": [],
      "source": [
        "# TODO: Predicted values vs true values visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D0tCIYfyFbp"
      },
      "source": [
        "It can also be useful to visualize the actual and predicted values over time, for a slice of time. Use the test data for this visualization. Create two subplots, both with time on the horizontal axis, but only including *the first 1000 rows* (50 seconds) in the data. On the vertical axis,\n",
        "\n",
        "-   for one subplot: show the actual X direction as a line of one color, and the predicted X direction as a line of another color.\n",
        "-   for the second subplot: show the actual Y direction as a line of one color, and the predicted Y direction as a line of another color.\n",
        "\n",
        "Make sure to carefully label each axis (including units on the time axis!), and label the data series (i.e. which color is the actual value and which is the predicted value). Use solid lines (not dashed or dotted). Use similar dimensions as the “velocity vs. time” plot above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-Nq-TKCyFbp"
      },
      "outputs": [],
      "source": [
        "# TODO: Predicted and true values over time visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8z0jUdvJyFbp"
      },
      "source": [
        "Comment on this plot - does the model predict the hand velocity well?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBc_Rs90yFbp"
      },
      "source": [
        "## 2. Fitting a model with delay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CMXH97fyFbp"
      },
      "source": [
        "One way we can improve the model accuracy is to add features using delayed version of the existing features.\n",
        "\n",
        "Specifically, the model we used above tries to predict velocity in direction $k$ at time $i$ using\n",
        "\n",
        "$$\\hat{y}_{i,k} = w_{k,0} + \\sum_{d=1}^{\\text{nneuron}} w_{k,d} X_{i,d}  $$\n",
        "\n",
        "In this model, $\\hat{y}_{i,k}$ at the $i$th time bin was only dependent on $X_i$, the number of spikes of each neuron in time bin $i$. In signal processing, this is called a *memoryless* model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WeneYSZyFbp"
      },
      "source": [
        "However, in many physical systems, such as those that arise in neuroscience, there is a delay between the inputs and outputs. To model this effect, we could add additional features to each row of data, representing the number of spikes of each neuron in the *previous* row. Then, the output at time $i$ would be modeled as the effect of the neurons firing in time $i$ *and* the effect of the neurons firing in time $i-1$.\n",
        "\n",
        "We wouldn’t be able to use data from the past for the first row of data, since we don’t *have* data about neurons firing in the previous time step. But we can drop that row. If our original data matrix had `nt` rows and `nneuron` columns, our data matrix with delayed features would have `nt - 1` rows and `nneuron + 1 x nneuron` columns. (The first `nneuron` columns represent the number of spikes in each neuron for the current time, the next `nneuron` columns represent the number of spikes in each neuron for the previous time.)\n",
        "\n",
        "Furthermore, we can “look back” any number of time steps, so that the output at time $i$ is modeled as the effect of the neurons firing in time $i$, the neurons firing in time $i-1$, ..., all the way up to the effect of the neurons firing in time $i- \\text{dly}$ (where $\\text{dly}$ is the maximum number of time steps we're going to “look back” on). Our data matrix with the additional delayed features would have `nt - dly` rows and `nneuron + dly x nneuron` columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q6bov8ayFbq"
      },
      "source": [
        "Here is a function that accepts `X` and `y` data and a `dly` argument, and returns `X` and `y` with delayed features up to `dly` time steps backward."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ak7JlcZ1yFbq"
      },
      "outputs": [],
      "source": [
        "def create_dly_data(X,y,dly):\n",
        "    \"\"\"\n",
        "    Create delayed data\n",
        "    \"\"\"\n",
        "    n,p = X.shape\n",
        "    Xdly = np.zeros((n-dly,(dly+1)*p))\n",
        "    for i in range(dly+1):\n",
        "        Xdly[:,i*p:(i+1)*p] = X[dly-i:n-i,:]\n",
        "    ydly = y[dly:]\n",
        "\n",
        "    return Xdly, ydly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu9bdoP6yFbq"
      },
      "source": [
        "To convince yourself that this works, try creating a data matrix that includes delayed features one time step back:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zg2ayofGyFbq"
      },
      "outputs": [],
      "source": [
        "X_dly_1, y_dly_1 = create_dly_data(X, y, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41zu8-IkyFbq"
      },
      "source": [
        "Verify that the dimensions have changed, as expected:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lJT3CviyFbq"
      },
      "outputs": [],
      "source": [
        "# dimensions of original data matrix\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyJpsKlcyFbr"
      },
      "outputs": [],
      "source": [
        "# dimensions of data matrix with delayed features 1 time step back\n",
        "X_dly_1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooCvPMtIyFbr"
      },
      "source": [
        "Check row 0 in the matrix with delayed features, and verify that it is the concatenation of row 1 and row 0 in the original data matrix. (Note that row 0 in the matrix with delayed features corresponds to row 1 in the original data matrix.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgRoLFAwyFbr"
      },
      "outputs": [],
      "source": [
        "X_dly_1[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25B2x-mRyFbr"
      },
      "outputs": [],
      "source": [
        "np.hstack((X[1], X[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJxSobB_yFbr"
      },
      "outputs": [],
      "source": [
        "y_dly_1[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0amEXDKyFbr"
      },
      "outputs": [],
      "source": [
        "y[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s83U4GlCyFbr"
      },
      "source": [
        "Now fit an linear delayed model with `dly=2` delay lags. That is,\n",
        "\n",
        "-   Create delayed data `X_dly_2, y_dly_2` by calling `create_dly_data` with `dly=2`\n",
        "-   Split the data (with the extra delay features!) into training and test as before (again, do not shuffle the data, and use a test size of 0.33). Name the training data `Xtr_dly_2, ytr_dly_2` and name the test data `Xts_dly_2, yts_dly_2`.\n",
        "-   Fit the model on the training data\n",
        "-   Use the model to predict the values for the test data and save the result in `yhat_dly_2`\n",
        "-   Measure the R2 score on the test data and save the result in `rsq_dly_2`. (Note: make sure you are comparing the model prediction to the “delayed” test data samples, not the original samples!)\n",
        "\n",
        "If you did this correctly, you should get a new R2 score around 0.60. This is significantly better than the memoryless model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bYG8clIyFbr"
      },
      "outputs": [],
      "source": [
        "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
        "\n",
        "# TODO: Fit a linear model with dly=2\n",
        "\n",
        "# Create the delayed data\n",
        "# X_dly_2, y_dly_2 = ...\n",
        "\n",
        "# Split into training and test\n",
        "# Xtr_dly_2, ytr_dly_2 = ...\n",
        "# Xts_dly_2, yts_dly_2 = ...\n",
        "\n",
        "# Create linear regression object\n",
        "\n",
        "# Fit the model\n",
        "\n",
        "# Predict values for test data\n",
        "# yhat_dly_2 = ...\n",
        "\n",
        "# Measure the new r2 score\n",
        "# rsq_dly_2 = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPPPO8FcyFbr"
      },
      "outputs": [],
      "source": [
        "rsq_dly_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdymGpOfyFbr"
      },
      "source": [
        "As before (with the same style requirements as before), plot the predicted vs. true values, but for the model with `dly=2`, with one subplot for X velocity and one subplot for Y velocity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQWLVfYeyFbr"
      },
      "outputs": [],
      "source": [
        "# TODO: Predicted values vs true values visualization with dly=2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFaIoEudyFbr"
      },
      "source": [
        "Also as you did before (with the same style requirements as before), plot the actual and predicted values over time for the first 1000 samples, for the model with `dly=2`. (Note: make sure you are comparing the model prediction to the “delayed” test data samples, not the original samples!)\n",
        "\n",
        "Does the model predict the hand velocity well?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrcR8pSNyFbr"
      },
      "outputs": [],
      "source": [
        "# TODO: Predicted and true values over time visualization with dly=2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-L_Aa_KyFbr"
      },
      "source": [
        "## 3. Selecting the optimal delay with K-fold CV\n",
        "\n",
        "In the previous example, we fixed `dly=2`. We will now select the optimal delay using K-fold cross validation.\n",
        "\n",
        "Since we have a large number of data samples, it will take a long time to run the K-fold CV for finding the optimal delay. So, to simplify things, we will just pretend that we have a very limited data set, `Xred` and `yred`. In this section, we’ll use the reduced data set `Xred` and `yred` in place of the original `X` and `y`.\n",
        "\n",
        "We will compute `Xred` and `yred` by taking the first `nred=6000` samples of the data `X` and `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXspG4ZlyFbr"
      },
      "outputs": [],
      "source": [
        "nred = 6000\n",
        "\n",
        "Xred = X[:nred]\n",
        "yred = y[:nred]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKXdjeEyyFbr"
      },
      "source": [
        "Note: since we are only using the first 6000 samples to train the model and select the best `dly`, there are plenty of samples left out as the test set. We don’t need to (and shouldn’t) further divide these 6000 samples into training and test sets - we can use all of it for model training and model selection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO30CqR2yFbr"
      },
      "source": [
        "We will look at model orders up to `dmax=15`. We will create a delayed data matrix, `X_dly_15,y_dly_15`, using `create_dly_data` with the reduced data `Xred,yred` and `dly=dmax`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8r6lt6VbyFbr"
      },
      "outputs": [],
      "source": [
        "dmax = 15\n",
        "X_dly_15, y_dly_15 = create_dly_data(Xred,yred,dmax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmEUHVkdyFbr"
      },
      "outputs": [],
      "source": [
        "X_dly_15.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ju6xFFbyFbr"
      },
      "outputs": [],
      "source": [
        "y_dly_15.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqwQcfTNyFbr"
      },
      "source": [
        "We are going to use K-fold CV with `nfold=10` to find the optimal delay, for all the values of delay in `dtest_list`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rldL4aVOyFbr"
      },
      "outputs": [],
      "source": [
        "dtest_list = np.arange(0, dmax+1)\n",
        "nd = len(dtest_list)\n",
        "\n",
        "print(dtest_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8MEKfyGyFbr"
      },
      "source": [
        "You can refer to the example in the “Model order selection” section of the demo notebook. But, make sure to use `shuffle=False` in your `KFold` object, since for this example it would be inappropriate to shuffle the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcXqnvSCyFbr"
      },
      "outputs": [],
      "source": [
        "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
        "\n",
        "\n",
        "# TODO: Use K-fold CV to select dly\n",
        "\n",
        "# Number of folds\n",
        "nfold = 10\n",
        "\n",
        "#  Create a k-fold object\n",
        "# kf = KFold(...)\n",
        "\n",
        "# Initialize a matrix rsq_kf to hold values of the R^2 across the model orders and folds.\n",
        "rsq_kf = np.zeros((nd,nfold))\n",
        "\n",
        "# Loop over the folds\n",
        "for i, idx_split in enumerate(kf.split(Xdly)):\n",
        "\n",
        "    # Get the training and validation data in the split\n",
        "    idx_tr, idx_val = idx_split\n",
        "\n",
        "    for it, dtest in enumerate(dtest_list):\n",
        "        # DO NOT call create_dly_data again\n",
        "        # just select the appropriate subset of columns of X_dly_15\n",
        "        # X_dtest = X_dly_15 with the columns corresponding to only the `dtest+1` most recent times.\n",
        "\n",
        "        # Split the data (X_dtest, y_dly_15) into training and validation\n",
        "        # using idx_tr and idx_val\n",
        "        # Xtr_kf = ...\n",
        "        # ytr_kf = ...\n",
        "        # Xval_kf = ...\n",
        "        # yval_kf = ...\n",
        "\n",
        "        # Fit linear regression on training data\n",
        "\n",
        "        #  Measure the R2 on validation data and store in the matrix rsq_kf\n",
        "        # yhat_kf = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvaPBqtRyFbs"
      },
      "source": [
        "Write code to find the delay that has the best mean validation R2. Get the best delay according to the “best R2” rule, and save it in `d_opt`. Print the value of `d_opt`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjC7h-w-yFbs"
      },
      "outputs": [],
      "source": [
        "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
        "\n",
        "# TODO: Use K-fold CV (continued)\n",
        "# d_opt = ...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKhD5ZhuyFbs"
      },
      "source": [
        "Now write code to find the best delay using the one SE rule (i.e. find the simplest model whose validation R2 is within one SE of the model with the best R2).\n",
        "\n",
        "-   get the “target R2” that is within one of the “best R2” model, and save it in `rsq_one_se_tgt`\n",
        "-   then get the delay of the simplest model with R2 greater than this target, and save it in `d_one_se`.\n",
        "\n",
        "Print the value of `d_one_se`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nwnv3uNdyFbs"
      },
      "outputs": [],
      "source": [
        "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
        "\n",
        "# TODO: Use K-fold CV (continued)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00LOPkDlyFbs"
      },
      "source": [
        "Plot the mean and standard error of the validation R2 values for each model (each delay value) as a function of the delay. Use a `plt.errorbar` plot, as shown in the “Model selection using 1-SE rule” section of the demo notebook. Label each axes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFE_bTx9yFbs"
      },
      "outputs": [],
      "source": [
        "# TODO: Visualize mean and SE of R2 across folds for each dly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dths7DFHyFbs"
      },
      "source": [
        "Look at the plot, and validate:\n",
        "\n",
        "-   Does the model with no delay have a similar validation R2 to the value you measured earlier for a memoryless model? (it should have been around 0.45.) You are working with a different (smaller) subset of the data now, so the R2 won’t be exactly the same as before, but it should be similar.\n",
        "-   Does the model with delay 2 have a similar validation R2 to the value you measured earlier for a delay 2 model? (it should have been around 0.60.) You are working with a different (smaller) subset of the data now, so the R2 won’t be exactly the same as before, but it should be similar.\n",
        "-   Does the trend (of validation R2 vs delay order) generally match your expectations?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dn5GKfnIyFbs"
      },
      "source": [
        "## 4. Fitting the selected model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pODKZlCOyFbs"
      },
      "source": [
        "Now that we have selected a model order, we can fit a linear regression model using the best delay according to the one SE rule.\n",
        "\n",
        "First, create an “best according to one-SE delay” training and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6LuhUyjyFbs"
      },
      "outputs": [],
      "source": [
        "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
        "\n",
        "# Un-comment this line:\n",
        "# X_dly_one_se, y_dly_one_se = create_dly_data(X, y, d_one_se)\n",
        "\n",
        "# Then, use train_test_split to create Xtr_dly_one_se, ytr_dly_one_se and Xts_dly_one_se, yts_dly_one_se\n",
        "# (using the same settings as before)\n",
        "# Xtr_dly_one_se, ytr_dly_one_se = ...\n",
        "# Xts_dly_one_se, yts_dly_one_se = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt95mnRMyFbs"
      },
      "source": [
        "Then, fit a linear model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5HXy5ibyFbs"
      },
      "outputs": [],
      "source": [
        "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
        "\n",
        "# TODO: Fit a linear model with `dly=d_one_se`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfcmky1CyFbs"
      },
      "source": [
        "Use your fitted model to get the predictions `yhat_dly_one_se` and find the R2 score `rsq_dly_one_se` on the test set.\n",
        "\n",
        "Print the value of `rsq_dly_one_se`. It should be substantially better than before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKLb9KYOyFbs"
      },
      "outputs": [],
      "source": [
        "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
        "\n",
        "# TODO: Fit a linear model with `dly=d_one_se` (continued)\n",
        "# yhat_dly_one_se = ...\n",
        "# rsq_dly_one_se = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zAhponHyFbs"
      },
      "source": [
        "Also plot the actual and predicted values over time for the first 1000 samples of the *test* data (similar to your plots in the previous sections, following the same style requirements). (Note: make sure you are comparing the model prediction to the “delayed” test data samples, not the original samples!)\n",
        "\n",
        "Comment on this plot - does the model predict the hand velocity well, compared to the previous models?\n",
        "\n",
        "See if you can identify a few points where this model does noticeably better. Download and *annotate* this plot - circle parts of the time series where the model with one-SE delay is noticably better at predicting the true value than the model with delay = 2.\n",
        "\n",
        "Comment on the versions of this plot you created for each of the three models (no delay, delay 2, delay with one-SE delay). What is the R2 score of the model in each case? Does the visual improvement you can see in the plot align with your expectations, based on the magnitude of the improvement in R2 score?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9jgZgCZyFbs"
      },
      "outputs": [],
      "source": [
        "# TODO: Predicted and true values over time for dly=d_one_se visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qfYNVRIyFbs"
      },
      "source": [
        "–\\>"
      ]
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "provenance": []
    }
  }
}